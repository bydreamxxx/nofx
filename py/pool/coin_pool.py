"""
å¸ç§æ± ç®¡ç†æ¨¡å—

æä¾›ä¸¤ç§å¸ç§æ± æ•°æ®æºï¼š
1. AI500 è¯„åˆ†å¸ç§æ± ï¼ˆå¤–éƒ¨APIï¼‰
2. OI Top æŒä»“é‡å¢é•¿Top20ï¼ˆå¤–éƒ¨APIï¼‰

æ”¯æŒï¼š
- é»˜è®¤ä¸»æµå¸ç§åˆ—è¡¨ï¼ˆBTCã€ETHã€SOLç­‰ï¼‰
- APIè·å–å¤±è´¥æ—¶è‡ªåŠ¨é™çº§åˆ°ç¼“å­˜
- ç¼“å­˜å¤±è´¥æ—¶ä½¿ç”¨é»˜è®¤å¸ç§
- é‡è¯•æœºåˆ¶
- å»é‡åˆå¹¶
"""

import os
import json
import httpx
from httpx_retry import AsyncRetryTransport, RetryPolicy
from pathlib import Path
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Any
from dataclasses import dataclass, field
from loguru import logger
from utils.http_config import get_http_proxy


# é»˜è®¤ä¸»æµå¸ç§åˆ—è¡¨
DEFAULT_MAINSTREAM_COINS = [
    "BTCUSDT",
    "ETHUSDT",
    "SOLUSDT",
    "BNBUSDT",
    "XRPUSDT",
    "DOGEUSDT",
    "ADAUSDT",
    "HYPEUSDT",
]


@dataclass
class CoinInfo:
    """å¸ç§ä¿¡æ¯"""
    pair: str  # äº¤æ˜“å¯¹ç¬¦å·ï¼ˆä¾‹å¦‚ï¼šBTCUSDTï¼‰
    score: float = 0.0  # å½“å‰è¯„åˆ†
    start_time: int = 0  # å¼€å§‹æ—¶é—´ï¼ˆUnixæ—¶é—´æˆ³ï¼‰
    start_price: float = 0.0  # å¼€å§‹ä»·æ ¼
    last_score: float = 0.0  # æœ€æ–°è¯„åˆ†
    max_score: float = 0.0  # æœ€é«˜è¯„åˆ†
    max_price: float = 0.0  # æœ€é«˜ä»·æ ¼
    increase_percent: float = 0.0  # æ¶¨å¹…ç™¾åˆ†æ¯”
    is_available: bool = True  # æ˜¯å¦å¯äº¤æ˜“


@dataclass
class OIPosition:
    """æŒä»“é‡æ•°æ®"""
    symbol: str
    rank: int = 0
    current_oi: float = 0.0  # å½“å‰æŒä»“é‡
    oi_delta: float = 0.0  # æŒä»“é‡å˜åŒ–
    oi_delta_percent: float = 0.0  # æŒä»“é‡å˜åŒ–ç™¾åˆ†æ¯”
    oi_delta_value: float = 0.0  # æŒä»“é‡å˜åŒ–ä»·å€¼
    price_delta_percent: float = 0.0  # ä»·æ ¼å˜åŒ–ç™¾åˆ†æ¯”
    net_long: float = 0.0  # å‡€å¤šä»“
    net_short: float = 0.0  # å‡€ç©ºä»“


@dataclass
class MergedCoinPool:
    """åˆå¹¶çš„å¸ç§æ± ï¼ˆAI500 + OI Topï¼‰"""
    ai500_coins: List[CoinInfo] = field(default_factory=list)
    oi_top_coins: List[OIPosition] = field(default_factory=list)
    all_symbols: List[str] = field(default_factory=list)
    symbol_sources: Dict[str, List[str]] = field(default_factory=dict)


class CoinPoolManager:
    """å¸ç§æ± ç®¡ç†å™¨"""

    def __init__(
        self,
        use_default_coins: bool = False,
        coin_pool_api_url: str = "",
        oi_top_api_url: str = "",
        cache_dir: str = "coin_pool_cache",
        timeout: float = 30.0,
    ):
        self.use_default_coins = use_default_coins
        self.coin_pool_api_url = coin_pool_api_url
        self.oi_top_api_url = oi_top_api_url
        self.cache_dir = cache_dir
        self.timeout = timeout

        # ç¡®ä¿ç¼“å­˜ç›®å½•å­˜åœ¨
        Path(self.cache_dir).mkdir(parents=True, exist_ok=True)

    def normalize_symbol(self, symbol: str) -> str:
        """æ ‡å‡†åŒ–å¸ç§ç¬¦å·"""
        symbol = symbol.strip().upper()
        if not symbol.endswith("USDT"):
            symbol = symbol + "USDT"
        return symbol

    async def get_coin_pool(self) -> List[CoinInfo]:
        """
        è·å–å¸ç§æ± åˆ—è¡¨ï¼ˆå¸¦é‡è¯•å’Œç¼“å­˜æœºåˆ¶ï¼‰

        ä¼˜å…ˆçº§ï¼š
        1. å¦‚æœå¯ç”¨é»˜è®¤å¸ç§ -> è¿”å›é»˜è®¤åˆ—è¡¨
        2. å¦‚æœé…ç½®äº†API -> ä»APIè·å–ï¼ˆå¤±è´¥æ—¶é‡è¯•ï¼‰
        3. APIå¤±è´¥ -> ä½¿ç”¨ç¼“å­˜
        4. ç¼“å­˜å¤±è´¥ -> ä½¿ç”¨é»˜è®¤å¸ç§
        """
        # ä¼˜å…ˆæ£€æŸ¥æ˜¯å¦å¯ç”¨é»˜è®¤å¸ç§
        if self.use_default_coins:
            logger.info("âœ“ å·²å¯ç”¨é»˜è®¤ä¸»æµå¸ç§åˆ—è¡¨")
            return self._convert_symbols_to_coins(DEFAULT_MAINSTREAM_COINS)

        # æ£€æŸ¥API URLæ˜¯å¦é…ç½®
        if not self.coin_pool_api_url.strip():
            logger.warning("âš ï¸  æœªé…ç½®å¸ç§æ± API URLï¼Œä½¿ç”¨é»˜è®¤ä¸»æµå¸ç§åˆ—è¡¨")
            return self._convert_symbols_to_coins(DEFAULT_MAINSTREAM_COINS)

        # å°è¯•ä»APIè·å–ï¼ˆå†…å±‚å·²æœ‰é‡è¯•æœºåˆ¶ï¼‰
        try:
            coins = await self._fetch_coin_pool()
            # æˆåŠŸè·å–åä¿å­˜åˆ°ç¼“å­˜
            await self._save_coin_pool_cache(coins)
            return coins

        except Exception as e:
            logger.error(f"âŒ APIè¯·æ±‚å¤±è´¥: {e}")

            # APIè·å–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ç¼“å­˜
            logger.warning("âš ï¸  å°è¯•ä½¿ç”¨å†å²ç¼“å­˜æ•°æ®...")
            try:
                cached_coins = await self._load_coin_pool_cache()
                logger.info(f"âœ“ ä½¿ç”¨å†å²ç¼“å­˜æ•°æ®ï¼ˆå…±{len(cached_coins)}ä¸ªå¸ç§ï¼‰")
                return cached_coins
            except Exception as cache_error:
                logger.warning(f"âš ï¸  æ— æ³•åŠ è½½ç¼“å­˜æ•°æ®: {cache_error}")

            # ç¼“å­˜ä¹Ÿå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤ä¸»æµå¸ç§
            logger.warning(f"âš ï¸  ä½¿ç”¨é»˜è®¤ä¸»æµå¸ç§åˆ—è¡¨")
            return self._convert_symbols_to_coins(DEFAULT_MAINSTREAM_COINS)

    async def _fetch_coin_pool(self) -> List[CoinInfo]:
        """å®é™…æ‰§è¡Œå¸ç§æ± è¯·æ±‚"""
        logger.info("ğŸ”„ æ­£åœ¨è¯·æ±‚AI500å¸ç§æ± ...")

        proxy = get_http_proxy()
        async with httpx.AsyncClient(
            proxy=proxy,
            transport=AsyncRetryTransport(policy=RetryPolicy().with_max_retries(3).with_min_delay(1).with_multiplier(2)),
            timeout=self.timeout
        ) as client:
            response = await client.get(self.coin_pool_api_url)
            response.raise_for_status()
            data = response.json()

            if not data.get("success"):
                raise ValueError("APIè¿”å›å¤±è´¥çŠ¶æ€")

            coin_data = data.get("data", {}).get("coins", [])
            if not coin_data:
                raise ValueError("å¸ç§åˆ—è¡¨ä¸ºç©º")

            # è§£æå¸ç§ä¿¡æ¯
            coins = []
            for item in coin_data:
                coin = CoinInfo(
                    pair=item.get("pair", ""),
                    score=float(item.get("score", 0)),
                    start_time=int(item.get("start_time", 0)),
                    start_price=float(item.get("start_price", 0)),
                    last_score=float(item.get("last_score", 0)),
                    max_score=float(item.get("max_score", 0)),
                    max_price=float(item.get("max_price", 0)),
                    increase_percent=float(item.get("increase_percent", 0)),
                    is_available=True,
                )
                coins.append(coin)

            logger.info(f"âœ“ æˆåŠŸè·å–{len(coins)}ä¸ªå¸ç§")
            return coins

    async def _save_coin_pool_cache(self, coins: List[CoinInfo]) -> None:
        """ä¿å­˜å¸ç§æ± åˆ°ç¼“å­˜æ–‡ä»¶"""
        cache_data = {
            "coins": [
                {
                    "pair": c.pair,
                    "score": c.score,
                    "start_time": c.start_time,
                    "start_price": c.start_price,
                    "last_score": c.last_score,
                    "max_score": c.max_score,
                    "max_price": c.max_price,
                    "increase_percent": c.increase_percent,
                }
                for c in coins
            ],
            "fetched_at": datetime.now().isoformat(),
            "source_type": "api",
        }

        cache_path = os.path.join(self.cache_dir, "latest.json")
        with open(cache_path, "w", encoding="utf-8") as f:
            json.dump(cache_data, f, indent=2, ensure_ascii=False)

        logger.info(f"ğŸ’¾ å·²ä¿å­˜å¸ç§æ± ç¼“å­˜ï¼ˆ{len(coins)}ä¸ªå¸ç§ï¼‰")

    async def _load_coin_pool_cache(self) -> List[CoinInfo]:
        """ä»ç¼“å­˜æ–‡ä»¶åŠ è½½å¸ç§æ± """
        cache_path = os.path.join(self.cache_dir, "latest.json")

        if not os.path.exists(cache_path):
            raise FileNotFoundError("ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨")

        with open(cache_path, "r", encoding="utf-8") as f:
            cache_data = json.load(f)

        # æ£€æŸ¥ç¼“å­˜å¹´é¾„
        fetched_at_str = cache_data.get("fetched_at", "")
        if fetched_at_str:
            fetched_at = datetime.fromisoformat(fetched_at_str)
            cache_age = datetime.now() - fetched_at

            if cache_age > timedelta(hours=24):
                logger.warning(
                    f"âš ï¸  ç¼“å­˜æ•°æ®è¾ƒæ—§ï¼ˆ{cache_age.total_seconds() / 3600:.1f}å°æ—¶å‰ï¼‰ï¼Œä½†ä»å¯ä½¿ç”¨"
                )
            else:
                logger.info(
                    f"ğŸ“‚ ç¼“å­˜æ•°æ®æ—¶é—´: {fetched_at.strftime('%Y-%m-%d %H:%M:%S')}ï¼ˆ{cache_age.total_seconds() / 60:.1f}åˆ†é’Ÿå‰ï¼‰"
                )

        # è§£æå¸ç§
        coins = []
        for item in cache_data.get("coins", []):
            coin = CoinInfo(
                pair=item.get("pair", ""),
                score=float(item.get("score", 0)),
                start_time=int(item.get("start_time", 0)),
                start_price=float(item.get("start_price", 0)),
                last_score=float(item.get("last_score", 0)),
                max_score=float(item.get("max_score", 0)),
                max_price=float(item.get("max_price", 0)),
                increase_percent=float(item.get("increase_percent", 0)),
                is_available=True,
            )
            coins.append(coin)

        return coins

    async def get_available_coins(self) -> List[str]:
        """è·å–å¯ç”¨çš„å¸ç§åˆ—è¡¨ï¼ˆè¿‡æ»¤ä¸å¯ç”¨çš„ï¼‰"""
        coins = await self.get_coin_pool()

        symbols = []
        for coin in coins:
            if coin.is_available:
                symbol = self.normalize_symbol(coin.pair)
                symbols.append(symbol)

        if not symbols:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„å¸ç§")

        return symbols

    async def get_top_rated_coins(self, limit: int) -> List[str]:
        """è·å–è¯„åˆ†æœ€é«˜çš„Nä¸ªå¸ç§ï¼ˆæŒ‰è¯„åˆ†ä»å¤§åˆ°å°æ’åºï¼‰"""
        coins = await self.get_coin_pool()

        # è¿‡æ»¤å¯ç”¨çš„å¸ç§
        available_coins = [c for c in coins if c.is_available]

        if not available_coins:
            raise ValueError("æ²¡æœ‰å¯ç”¨çš„å¸ç§")

        # æŒ‰Scoreé™åºæ’åº
        available_coins.sort(key=lambda x: x.score, reverse=True)

        # å–å‰Nä¸ª
        max_count = min(limit, len(available_coins))
        symbols = [
            self.normalize_symbol(available_coins[i].pair) for i in range(max_count)
        ]

        return symbols

    def _convert_symbols_to_coins(self, symbols: List[str]) -> List[CoinInfo]:
        """å°†å¸ç§ç¬¦å·åˆ—è¡¨è½¬æ¢ä¸ºCoinInfoåˆ—è¡¨"""
        return [
            CoinInfo(pair=symbol, score=0, is_available=True) for symbol in symbols
        ]

    # ========== OI Topï¼ˆæŒä»“é‡å¢é•¿Top20ï¼‰æ•°æ® ==========

    async def get_oi_top_positions(self) -> List[OIPosition]:
        """
        è·å–æŒä»“é‡å¢é•¿Top20æ•°æ®ï¼ˆå¸¦é‡è¯•å’Œç¼“å­˜ï¼‰

        è¿”å›ç©ºåˆ—è¡¨å¦‚æœï¼š
        - æœªé…ç½®API URL
        - APIå’Œç¼“å­˜éƒ½å¤±è´¥
        """
        # æ£€æŸ¥API URLæ˜¯å¦é…ç½®
        if not self.oi_top_api_url.strip():
            logger.warning("âš ï¸  æœªé…ç½®OI Top API URLï¼Œè·³è¿‡OI Topæ•°æ®è·å–")
            return []

        # å°è¯•ä»APIè·å–ï¼ˆå†…å±‚å·²æœ‰é‡è¯•æœºåˆ¶ï¼‰
        try:
            positions = await self._fetch_oi_top()
            # æˆåŠŸè·å–åä¿å­˜åˆ°ç¼“å­˜
            await self._save_oi_top_cache(positions)
            return positions

        except Exception as e:
            logger.error(f"âŒ OI Top APIè¯·æ±‚å¤±è´¥: {e}")

            # APIè·å–å¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ç¼“å­˜
            logger.warning("âš ï¸  å°è¯•ä½¿ç”¨å†å²ç¼“å­˜æ•°æ®...")
            try:
                cached_positions = await self._load_oi_top_cache()
                logger.info(f"âœ“ ä½¿ç”¨å†å²OI Topç¼“å­˜æ•°æ®ï¼ˆå…±{len(cached_positions)}ä¸ªå¸ç§ï¼‰")
                return cached_positions
            except Exception as cache_error:
                logger.warning(f"âš ï¸  æ— æ³•åŠ è½½OI Topç¼“å­˜æ•°æ®: {cache_error}")

            # ç¼“å­˜ä¹Ÿå¤±è´¥ï¼Œè¿”å›ç©ºåˆ—è¡¨ï¼ˆOI Topæ˜¯å¯é€‰çš„ï¼‰
            logger.warning(f"âš ï¸  è·³è¿‡OI Topæ•°æ®")
            return []

    async def _fetch_oi_top(self) -> List[OIPosition]:
        """å®é™…æ‰§è¡ŒOI Topè¯·æ±‚"""
        logger.info("ğŸ”„ æ­£åœ¨è¯·æ±‚OI Topæ•°æ®...")

        proxy = get_http_proxy()
        async with httpx.AsyncClient(
            proxy=proxy,
            transport=AsyncRetryTransport(policy=RetryPolicy().with_max_retries(3).with_min_delay(1).with_multiplier(2)),
            timeout=self.timeout
        ) as client:
            response = await client.get(self.oi_top_api_url)
            response.raise_for_status()
            data = response.json()

            if not data.get("success"):
                raise ValueError("OI Top APIè¿”å›å¤±è´¥çŠ¶æ€")

            positions_data = data.get("data", {}).get("positions", [])
            time_range = data.get("data", {}).get("time_range", "")

            if not positions_data:
                raise ValueError("OI TopæŒä»“åˆ—è¡¨ä¸ºç©º")

            # è§£ææŒä»“ä¿¡æ¯
            positions = []
            for item in positions_data:
                pos = OIPosition(
                    symbol=item.get("symbol", ""),
                    rank=int(item.get("rank", 0)),
                    current_oi=float(item.get("current_oi", 0)),
                    oi_delta=float(item.get("oi_delta", 0)),
                    oi_delta_percent=float(item.get("oi_delta_percent", 0)),
                    oi_delta_value=float(item.get("oi_delta_value", 0)),
                    price_delta_percent=float(item.get("price_delta_percent", 0)),
                    net_long=float(item.get("net_long", 0)),
                    net_short=float(item.get("net_short", 0)),
                )
                positions.append(pos)

            logger.info(f"âœ“ æˆåŠŸè·å–{len(positions)}ä¸ªOI Topå¸ç§ï¼ˆæ—¶é—´èŒƒå›´: {time_range}ï¼‰")
            return positions

    async def _save_oi_top_cache(self, positions: List[OIPosition]) -> None:
        """ä¿å­˜OI Topæ•°æ®åˆ°ç¼“å­˜"""
        cache_data = {
            "positions": [
                {
                    "symbol": p.symbol,
                    "rank": p.rank,
                    "current_oi": p.current_oi,
                    "oi_delta": p.oi_delta,
                    "oi_delta_percent": p.oi_delta_percent,
                    "oi_delta_value": p.oi_delta_value,
                    "price_delta_percent": p.price_delta_percent,
                    "net_long": p.net_long,
                    "net_short": p.net_short,
                }
                for p in positions
            ],
            "fetched_at": datetime.now().isoformat(),
            "source_type": "api",
        }

        cache_path = os.path.join(self.cache_dir, "oi_top_latest.json")
        with open(cache_path, "w", encoding="utf-8") as f:
            json.dump(cache_data, f, indent=2, ensure_ascii=False)

        logger.info(f"ğŸ’¾ å·²ä¿å­˜OI Topç¼“å­˜ï¼ˆ{len(positions)}ä¸ªå¸ç§ï¼‰")

    async def _load_oi_top_cache(self) -> List[OIPosition]:
        """ä»ç¼“å­˜åŠ è½½OI Topæ•°æ®"""
        cache_path = os.path.join(self.cache_dir, "oi_top_latest.json")

        if not os.path.exists(cache_path):
            raise FileNotFoundError("OI Topç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨")

        with open(cache_path, "r", encoding="utf-8") as f:
            cache_data = json.load(f)

        # æ£€æŸ¥ç¼“å­˜å¹´é¾„
        fetched_at_str = cache_data.get("fetched_at", "")
        if fetched_at_str:
            fetched_at = datetime.fromisoformat(fetched_at_str)
            cache_age = datetime.now() - fetched_at

            if cache_age > timedelta(hours=24):
                logger.warning(
                    f"âš ï¸  OI Topç¼“å­˜æ•°æ®è¾ƒæ—§ï¼ˆ{cache_age.total_seconds() / 3600:.1f}å°æ—¶å‰ï¼‰ï¼Œä½†ä»å¯ä½¿ç”¨"
                )
            else:
                logger.info(
                    f"ğŸ“‚ OI Topç¼“å­˜æ•°æ®æ—¶é—´: {fetched_at.strftime('%Y-%m-%d %H:%M:%S')}ï¼ˆ{cache_age.total_seconds() / 60:.1f}åˆ†é’Ÿå‰ï¼‰"
                )

        # è§£ææŒä»“
        positions = []
        for item in cache_data.get("positions", []):
            pos = OIPosition(
                symbol=item.get("symbol", ""),
                rank=int(item.get("rank", 0)),
                current_oi=float(item.get("current_oi", 0)),
                oi_delta=float(item.get("oi_delta", 0)),
                oi_delta_percent=float(item.get("oi_delta_percent", 0)),
                oi_delta_value=float(item.get("oi_delta_value", 0)),
                price_delta_percent=float(item.get("price_delta_percent", 0)),
                net_long=float(item.get("net_long", 0)),
                net_short=float(item.get("net_short", 0)),
            )
            positions.append(pos)

        return positions

    async def get_oi_top_symbols(self) -> List[str]:
        """è·å–OI Topçš„å¸ç§ç¬¦å·åˆ—è¡¨"""
        positions = await self.get_oi_top_positions()
        return [self.normalize_symbol(p.symbol) for p in positions]

    async def get_merged_coin_pool(self, ai500_limit: int = 20) -> MergedCoinPool:
        """
        è·å–åˆå¹¶åçš„å¸ç§æ± ï¼ˆAI500 + OI Topï¼Œå»é‡ï¼‰

        Args:
            ai500_limit: AI500å–å‰Nä¸ªè¯„åˆ†æœ€é«˜çš„å¸ç§

        Returns:
            åˆå¹¶åçš„å¸ç§æ± ï¼ŒåŒ…å«æ¥æºæ ‡è®°
        """
        # 1. è·å–AI500æ•°æ®
        try:
            ai500_symbols = await self.get_top_rated_coins(ai500_limit)
        except Exception as e:
            logger.warning(f"âš ï¸  è·å–AI500æ•°æ®å¤±è´¥: {e}")
            ai500_symbols = []

        # 2. è·å–OI Topæ•°æ®
        try:
            oi_top_symbols = await self.get_oi_top_symbols()
        except Exception as e:
            logger.warning(f"âš ï¸  è·å–OI Topæ•°æ®å¤±è´¥: {e}")
            oi_top_symbols = []

        # 3. åˆå¹¶å¹¶å»é‡
        symbol_set = set()
        symbol_sources: Dict[str, List[str]] = {}

        # æ·»åŠ AI500å¸ç§
        for symbol in ai500_symbols:
            symbol_set.add(symbol)
            if symbol not in symbol_sources:
                symbol_sources[symbol] = []
            symbol_sources[symbol].append("ai500")

        # æ·»åŠ OI Topå¸ç§
        for symbol in oi_top_symbols:
            symbol_set.add(symbol)
            if symbol not in symbol_sources:
                symbol_sources[symbol] = []
            symbol_sources[symbol].append("oi_top")

        # è½¬æ¢ä¸ºåˆ—è¡¨
        all_symbols = list(symbol_set)

        # è·å–å®Œæ•´æ•°æ®
        try:
            ai500_coins = await self.get_coin_pool()
        except Exception:
            ai500_coins = []

        try:
            oi_top_positions = await self.get_oi_top_positions()
        except Exception:
            oi_top_positions = []

        merged = MergedCoinPool(
            ai500_coins=ai500_coins,
            oi_top_coins=oi_top_positions,
            all_symbols=all_symbols,
            symbol_sources=symbol_sources,
        )

        logger.info(
            f"ğŸ“Š å¸ç§æ± åˆå¹¶å®Œæˆ: AI500={len(ai500_symbols)}, OI_Top={len(oi_top_symbols)}, æ€»è®¡(å»é‡)={len(all_symbols)}"
        )

        return merged

    async def _async_sleep(self, seconds: float) -> None:
        """å¼‚æ­¥ç¡çœ ï¼ˆé¿å…å¯¼å…¥asyncioï¼‰"""
        import asyncio

        await asyncio.sleep(seconds)
